{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid19  Intervention Scoring using SageMaker\n",
    "### Primary objectives:\n",
    "1. Score / weigh effectiveness of each intervention for various countries using a weighted combination of scoring methods\n",
    "2. Assign a daily aggregated intervention score for each country using the calculated intervention weights - these scores will be used for case count projection\n",
    "\n",
    "We appreciate that users might not have the required CPU or memory to run the ML operations locally, hence we are providing this notebook in addition to the standalone notebook (interventions_scorer.ipynb), so that users can off-load the compute and memory heavy operations to Amazon SageMaker, a cloud based ML platform from AWS\n",
    "\n",
    "We'll use SageMaker Processing to push a processing script to a SageMaker managed container created from a user provided docker image. So we'll start by creating the docker image with all the required python libraries and our custom python modules and helper scripts. Once the docker image is built, we'll push them to Amazon Elastic Container Registry (ECR) service so that SageMaker can use it to locate and launch the container from this image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerize the core simulation modules and push the image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name='covid19-simulation'\n",
    "\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ScriptProcessor object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput\n",
    "import boto3\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = 'covid19_sagemaker_exec' #get_execution_role()\n",
    "ecr_repository = 'covid19-simulation'\n",
    "tag = ':latest'\n",
    "uri_suffix = 'amazonaws.com'\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    uri_suffix = 'amazonaws.com.cn'\n",
    "covid_repository_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, ecr_repository + tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_processor = ScriptProcessor(base_job_name='covid19-simulation',\n",
    "                                  image_uri=covid_repository_uri,\n",
    "                                  command=['python'],\n",
    "                                  role=role,\n",
    "                                  instance_count=1,\n",
    "                                  instance_type='ml.r5.xlarge',\n",
    "                                  max_runtime_in_seconds=1200,\n",
    "                                  env={'mode': 'python'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive the Effectiveness Score for different interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the publicly available data from https://oxcgrtportal.azurewebsites.net/api/CSVDownload for our experiments. But feel free to use any other more granular data following similar data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source the data appropriately and upload it to S3 bucket\n",
    "\n",
    "In our case, we can download the latest intervention data as <i>OxCGRT_Download_Full.csv</i>  from the URL above into <i>../data</i> folder before running the subsequent code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import urllib\n",
    "sys.path.insert(1, 'src')\n",
    "import config\n",
    "\n",
    "# Set this flag to True if you want to download the latest COVID19 intervention data from respective web source\n",
    "# Set it as False in case of subsequent runs on the same day.\n",
    "LOAD_LATEST_DATA = True\n",
    "    \n",
    "if LOAD_LATEST_DATA:\n",
    "    url = config.oxcgrt_intervention_data_online\n",
    "    local_file = os.path.join(config.base_data_dir, config.oxcgrt_intervention_data_offline)\n",
    "    #try:\n",
    "    with urllib.request.urlopen(url) as response, open(local_file, 'wb') as out_file:\n",
    "        data = response.read() # a `bytes` object\n",
    "        out_file.write(data)\n",
    "        print ('Downloaded latest data from: {}'.format(url))\n",
    "#     except Exception as e:\n",
    "#         print ('Error while downloading {}: {}'.format(url, e.__class__)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith('s3://')\n",
    "    split = s3_path.split('/')\n",
    "    bucket = split[2]\n",
    "    path = '/'.join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "    \n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print('File already exists.\\nSet override to upload anyway.\\n')\n",
    "            return\n",
    "        else:\n",
    "            print('Overwriting existing file')\n",
    "    with open(local_file, 'rb') as data:\n",
    "        print('Uploading file to {}'.format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set your S3 bucket name here\n",
    "bucket_name = 'covid19-sim-dummy'\n",
    "input_prefix = 'covid19'\n",
    "input_file_name = 'OxCGRT_Download_Full.csv'\n",
    "local_path = 'data/input/{}'.format(input_file_name)\n",
    "s3_data_path = 's3://{}/{}/{}'.format(bucket_name, input_prefix, input_file_name)\n",
    "\n",
    "s3_output_path = 's3://{}/{}/{}'.format(bucket_name, input_prefix, 'intervention_impact')\n",
    "buk = s3.Bucket(bucket_name)\n",
    "if len(list(buk.objects.filter(Prefix=\"{}/{}/{}\".format(bucket_name, input_prefix, 'intervention_impact')))) == 0:\n",
    "    dir_name = \"{}/{}/{}/\".format(bucket_name, input_prefix, 'intervention_impact')\n",
    "    s3_serv = boto3.client('s3')\n",
    "    s3_serv.put_object(Bucket=bucket_name, Key=(dir_name))\n",
    "    print ('Created directory: {}/{}/{}/'.format(bucket_name, input_prefix, 'intervention_impact'))\n",
    "    \n",
    "print(s3_data_path)\n",
    "\n",
    "copy_to_s3(local_path, s3_data_path, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Intervention Scoring script\n",
    "\n",
    "This script is the entry point to the intervention score computation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile intervention_scorer.py\n",
    "import sys\n",
    "sys.path.insert(1, '/opt/program')\n",
    "import config\n",
    "config.sagemaker_run = True\n",
    "config.base_data_dir = config.base_data_dir_sagemaker\n",
    "config.base_output_dir = config.base_output_dir_sagemaker \n",
    "\n",
    "import intervention_effectiveness_scorer as intv_scorer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #args, _ = parser.parse_known_args()\n",
    "    # Convert command line args into a map of args\n",
    "    args_iter = iter(sys.argv[1:])\n",
    "    args = dict(zip(args_iter, args_iter))\n",
    "    \n",
    "    #Data source for the whole analysis\n",
    "    intv_scorer.data_src = args['data_src']\n",
    "    #Select a country only if it has exceeded the conf_cases_threshold\n",
    "    intv_scorer.conf_cases_threshold = int(args['conf_cases_threshold'])\n",
    "    #Select records having confirmed cases >= min_case_threshold\n",
    "    intv_scorer.min_case_threshold = int(args['min_case_threshold'])\n",
    "    #window for rollong averages of conf case counts\n",
    "    intv_scorer.smoothing_window_len = int(args['smoothing_window_len'])\n",
    "    #number of lags to use for time-series style modeling of conf cases\n",
    "    intv_scorer.num_lags = int(args['num_lags'])\n",
    "    #Skip a few recent dayes data for potential missing values\n",
    "    intv_scorer.recent_days_to_skip = int(args['recent_days_to_skip'])\n",
    "    #median incubation period for Covid19\n",
    "    intv_scorer.incubation_period = int(args['incubation_period'])\n",
    "    \n",
    "    #Export location of intervention scores\n",
    "    analysis_outcome_export_loc = args['analysis_outcome_export_loc']\n",
    "    #Export location of weighted & aggregated intervention scores\n",
    "    aggregated_intervention_scores_export_loc = args['aggregated_intervention_scores_export_loc']\n",
    "    \n",
    "    fit_stringency_index = 0.5\n",
    "    fit_conf_cases = 0.25\n",
    "    fit_intv_effect = 0.25\n",
    "    if 'fit_stringency_index' in args:\n",
    "        fit_stringency_index = float(args['fit_stringency_index'])\n",
    "    if 'fit_conf_cases' in args:\n",
    "        fit_conf_cases = float(args['fit_conf_cases'])\n",
    "    if 'fit_intv_effect' in args:\n",
    "        fit_intv_effect = float(args['fit_intv_effect'])\n",
    "    \n",
    "    intv_scorer.intervention_scoring_methods = {'fit_stringency_index':fit_stringency_index, \n",
    "                                    'fit_conf_cases':fit_conf_cases, \n",
    "                                    'fit_intv_effect':fit_intv_effect}\n",
    "      \n",
    "    if 'selected_countries' in args:\n",
    "        selected_countries = args['selected_countries']\n",
    "    \n",
    "    # Calculating relative weights/importance of different interventions\n",
    "    data_all, selected_countries, all_country_intv_scores = intv_scorer.score_interventions (selected_countries=None)\n",
    "    all_country_intv_scores.to_csv(analysis_outcome_export_loc, index=False)\n",
    "    \n",
    "    interventions = all_country_intv_scores['intervention'].unique().tolist()\n",
    "    relevant_cols = ['CountryName', 'CountryCode', 'ConfirmedCases', 'ConfirmedDeaths', 'StringencyIndex'] + interventions\n",
    "    data_filtered = data_all.loc[data_all['CountryCode'].isin(selected_countries), relevant_cols].copy()\n",
    "    data_filtered.reset_index(inplace=True)\n",
    "    data_filtered.fillna(0, inplace=True)\n",
    "    # Assign an aggregated intervention score for each country, each day\n",
    "    data_filtered = intv_scorer.assign_weighted_aggregations (data_filtered, all_country_intv_scores, selected_countries)\n",
    "    data_filtered.to_csv(aggregated_intervention_scores_export_loc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch the Intervention scoring on SageMaker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "import shutil\n",
    "\n",
    "data_src = '/opt/ml/processing/input/OxCGRT_Download_Full.csv'\n",
    "selected_countries = ''\n",
    "#Select a country only if it has exceeded the conf_cases_threshold\n",
    "conf_cases_threshold = 10000\n",
    "#Select records having confirmed cases >= min_case_threshold\n",
    "min_case_threshold = 0\n",
    "#window for rollong averages of conf case counts\n",
    "smoothing_window_len = 3\n",
    "#number of lags to use for time-series style modeling of conf cases\n",
    "num_lags = 1\n",
    "#Skip a few recent dayes data for potential missing values\n",
    "recent_days_to_skip = 5 \n",
    "#median incubation period for Covid19\n",
    "incubation_period = 5\n",
    "\n",
    "fit_stringency_index = 0.5\n",
    "fit_conf_cases = 0.5\n",
    "fit_intv_effect = 0.0\n",
    "\n",
    "#Export location of intervention scores\n",
    "analysis_outcome_export_loc = '/opt/ml/processing/out/countries_intervention_impacts.csv'\n",
    "#Export location of weighted & aggregated intervention scores\n",
    "aggregated_intervention_scores_export_loc = '/opt/ml/processing/out/countries_aggr_intervention_scores.csv'\n",
    "\n",
    "\n",
    "covid_processor.run(code='intervention_scorer.py',\n",
    "                      inputs=[ProcessingInput(\n",
    "                        source=s3_data_path,\n",
    "                        input_name='OxCGRT_Download_Full.csv',\n",
    "                        destination='/opt/ml/processing/input')], \n",
    "                      outputs=[ProcessingOutput(output_name='simulation_output',\n",
    "                                                source='/opt/ml/processing/out',\n",
    "                                                destination=s3_output_path)],\n",
    "                      arguments=['data_src', data_src, \\\n",
    "                                 'conf_cases_threshold', str(conf_cases_threshold), 'min_case_threshold', str(min_case_threshold), \\\n",
    "                                 'smoothing_window_len', str(smoothing_window_len), 'num_lags', str(num_lags), \\\n",
    "                                 'recent_days_to_skip', str(recent_days_to_skip), 'incubation_period', str(incubation_period), \\\n",
    "                                 'analysis_outcome_export_loc', analysis_outcome_export_loc, \\\n",
    "                                 'aggregated_intervention_scores_export_loc', aggregated_intervention_scores_export_loc, \\\n",
    "                                 'fit_stringency_index', str(fit_stringency_index), 'fit_conf_cases', str(fit_conf_cases), \\\n",
    "                                 'fit_intv_effect', str(fit_intv_effect)], \n",
    "                     logs=True)\n",
    "\n",
    "preprocessing_job_description = covid_processor.jobs[-1].describe()\n",
    "\n",
    "preprocessing_job_description\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the results back in your local environment\n",
    "The intervention scoring results need to be downloaded from S3 as those would be required while running the Simulation process (covid19_simulator_sagemker.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp 's3://covid19-sim-dummy/covid19/intervention_impact/countries_intervention_impacts.csv' ./data/input\n",
    "!aws s3 cp 's3://covid19-sim-dummy/covid19/intervention_impact/countries_aggr_intervention_scores.csv' ./data/input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
