{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid19 Projection using SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to run Covid-19 case projections at State or Country levels. The outcome is the projection of the total confirmed cases for the target geography. Please refer to covid19_simulator.ipynb for more details.\n",
    "\n",
    "We appreciate that users might not have the required CPU and memory to run the simulation-related operations locally, hence we are providing this notebook in addition to the core simulation notebook (covid19_simulator.ipynb), so that users can off-load the compute and memory heavy operations to Amazon SageMaker, a cloud based ML platform from AWS\n",
    "\n",
    "We'll use SageMaker Processing to push a processing script to a SageMaker managed container created from a user provided docker image. So we'll start by creating the docker image with all the required python libraries and our custom python modules and helper scripts. Once the docker image is built, we'll push them to Amazon Elastic Container Registry (ECR) service so that SageMaker can use it to locate and launch the container from this image.\n",
    "\n",
    "Note: interventions_scorer_sagemaker.ipynb should be excuted prior to running the projections on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dockerize the core simulation modules and push the image to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name='covid19-simulation'\n",
    "\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a ScriptProcessor object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import shutil\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = 'covid19_sagemaker_exec' #sagemaker.get_execution_role()\n",
    "ecr_repository = 'covid19-simulation'\n",
    "tag = ':latest'\n",
    "uri_suffix = 'amazonaws.com'\n",
    "if region in ['cn-north-1', 'cn-northwest-1']:\n",
    "    uri_suffix = 'amazonaws.com.cn'\n",
    "covid_repository_uri = '{}.dkr.ecr.{}.{}/{}'.format(account_id, region, uri_suffix, ecr_repository + tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_processor = ScriptProcessor(base_job_name='covid19-simulation',\n",
    "                                  image_uri=covid_repository_uri,\n",
    "                                  command=['python'],\n",
    "                                  role=role,\n",
    "                                  instance_count=1,\n",
    "                                  instance_type='ml.r5.xlarge',\n",
    "                                  max_runtime_in_seconds=1200,\n",
    "                                  env={'mode': 'python'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refresh latest data in local project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import urllib\n",
    "sys.path.insert(1, 'src')\n",
    "import config\n",
    "import state_data_loader\n",
    "import country_data_loader\n",
    "\n",
    "# Set this flag to True if you want to download the latest COVID19 cases data from respective web sources\n",
    "LOAD_LATEST_DATA = True\n",
    "\n",
    "if LOAD_LATEST_DATA:\n",
    "    \n",
    "    # Function to refresh the local data file with the latest version from the web\n",
    "    def download_latest_data (url, local_file):\n",
    "        with urllib.request.urlopen(url) as response, open(local_file, 'wb') as out_file:\n",
    "            data = response.read() # a `bytes` object\n",
    "            out_file.write(data)\n",
    "    \n",
    "    # Mapping of online vs offline file locations to refresh\n",
    "    online_offline_data = list()\n",
    "    # Confirmed cases data maintained by Johns Hopkins University\n",
    "    online_offline_data.append((config.confirmed_cases_global_online, \n",
    "                                os.path.join(config.base_data_dir, config.confirmed_cases_global_offline)))\n",
    "    # Recovered cases data maintained by Johns Hopkins University\n",
    "    online_offline_data.append((config.recovered_cases_global_online, \n",
    "                                os.path.join(config.base_data_dir, config.recovered_cases_global_offline)))\n",
    "    # Deceased cases data maintained by Johns Hopkins University\n",
    "    online_offline_data.append((config.deceased_cases_global_online, \n",
    "                                os.path.join(config.base_data_dir, config.deceased_cases_global_offline)))\n",
    "    # Indian states specific cases maintained by COVID19INDIA (www.covid19india.org)\n",
    "    online_offline_data.append((config.india_states_cases_online, \n",
    "                                os.path.join(config.base_data_dir, config.india_states_cases_offline)))\n",
    "    \n",
    "    # Refresh the local data files with the latest versions from respective web sources\n",
    "    for path_pair in online_offline_data:\n",
    "        try:\n",
    "            download_latest_data (path_pair[0], path_pair[1])\n",
    "            print ('Downloaded latest data from: {}'.format(path_pair[0]))\n",
    "        except Exception as e:\n",
    "            print ('Error while downloading {}: {}'.format(path_pair[0], e.__class__))\n",
    "    \n",
    "    # Transform and write the coutry specific data for further processing\n",
    "    country_data_loader.load()\n",
    "    \n",
    "    target_states = ['KA', 'KL', 'MH', 'GJ', 'WB']\n",
    "    # Transform and write the Indian states specific data for further processing\n",
    "    state_data_loader.load('India', target_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data to your s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith('s3://')\n",
    "    split = s3_path.split('/')\n",
    "    bucket = split[2]\n",
    "    path = '/'.join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "    \n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print('File already exists.\\nSet override to upload anyway.\\n')\n",
    "            return\n",
    "        else:\n",
    "            print('Overwriting existing file')\n",
    "    with open(local_file, 'rb') as data:\n",
    "        print('Uploading file to {}'.format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A sample simulation for the Indian state of Kerala\n",
    "state = 'KL'\n",
    "LOAD_STATE_DATA = False\n",
    "\n",
    "#set your S3 bucket name here\n",
    "bucket_name = 'covid19-sim-dummy'\n",
    "input_prefix = 'covid19'\n",
    "local_path = '../data/input/Cases_{}.csv'.format(state)\n",
    "s3_data_path = 's3://{}/{}/input.tar.gz'.format(bucket_name, input_prefix, state)\n",
    "print(s3_data_path)\n",
    "\n",
    "shutil.make_archive('input', 'gztar', 'data/input')\n",
    "\n",
    "copy_to_s3('input.tar.gz', s3_data_path, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the simulation initiation script\n",
    "This script is the entry point to the simulation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile simulation_enabler.py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import tarfile\n",
    "import shutil\n",
    "import inspect\n",
    "sys.path.insert(1, '/opt/program')\n",
    "\n",
    "import config\n",
    "config.sagemaker_run = True\n",
    "config.base_data_dir = config.base_data_dir_sagemaker\n",
    "config.base_output_dir = config.base_output_dir_sagemaker \n",
    "\n",
    "import state_data_loader\n",
    "import country_data_loader\n",
    "import simulation_orchestrator\n",
    "\n",
    "if __name__=='__main__':\n",
    "    shutil.unpack_archive(os.path.join(config.base_data_dir,'input.tar.gz'), config.base_data_dir,'gztar')\n",
    "    \n",
    "    # Convert command line args into a map of args\n",
    "    args_iter = iter(sys.argv[1:])\n",
    "    args = dict(zip(args_iter, args_iter))\n",
    "    \n",
    "    learn_params_flag = True if args['learn_params']=='True' else False\n",
    "    country_level_projection_flag = True if args['country_level_projection']=='True' else False   \n",
    "    \n",
    "    simulation_orchestrator.run(args['country_code'], args['state'], int(args['state_population']), \n",
    "                                int(args['actual_testing_capacity']), int(args['fitment_days']), \n",
    "                                int(args['test_days']), int(args['projection_days']), learn_params_flag, \n",
    "                                country_level_projection=country_level_projection_flag, intervention_influence_pctg=float(args['intervention_influence_pctg']))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the Simulation on SageMaker\n",
    "You start the simulation by calling the <i>run</i> function on the <i>ScriptProcessor</i> object and passing the <i>simulation_orchestrator.py</i> script along with other parameters like input and output locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "import shutil\n",
    "\n",
    "# A sample simulation for the Indian state of Kerala\n",
    "learn_params = True\n",
    "country_level_projection = False\n",
    "fitment_days = 14\n",
    "test_days = 5\n",
    "projection_days = 270\n",
    "intervention_influence_pctg = 0.8\n",
    "country_code, state, state_population, actual_testing_capacity = 'IND', 'KL', 33406061, 2800\n",
    "\n",
    "out_prefix = 'covid-19-out'\n",
    "\n",
    "s3_out_path = 's3://{}/{}'.format(bucket_name, out_prefix)\n",
    "\n",
    "covid_processor.run(code='simulation_enabler.py',\n",
    "                        inputs=[ProcessingInput(\n",
    "                        source=s3_data_path,\n",
    "                        input_name='input.tar.gz',\n",
    "                        destination='/opt/ml/processing/input')], \n",
    "                        outputs=[ProcessingOutput(output_name='param_file',\n",
    "                                                source='/opt/ml/processing/param',\n",
    "                                                destination=''),\n",
    "                        ProcessingOutput(output_name='simulation_output',\n",
    "                                                source='/opt/ml/processing/out',\n",
    "                                                destination=s3_out_path)],\n",
    "                        arguments=['country_code', country_code, 'state', state, 'state_population', str(state_population), \n",
    "                                 'actual_testing_capacity', str(actual_testing_capacity),'fitment_days', str(fitment_days), \n",
    "                                 'test_days', str(test_days), 'projection_days', str(projection_days), 'learn_params', str(learn_params), \n",
    "                                 'load_state_data', str(LOAD_STATE_DATA), 'country_level_projection', str(country_level_projection), \n",
    "                                 'intervention_influence_pctg', str(intervention_influence_pctg)], #, '--country_projection', country_projection]\n",
    "                        logs=True\n",
    "                \n",
    "                     )\n",
    "\n",
    "preprocessing_job_description = covid_processor.jobs[-1].describe()\n",
    "\n",
    "preprocessing_job_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
